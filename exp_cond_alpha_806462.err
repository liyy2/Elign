
CondaError: Run 'conda init' before 'conda deactivate'

wandb: Appending key for api.wandb.ai to your netrc file: /home/yl2428/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
The token `new token` has been saved to /home/yl2428/.cache/huggingface/stored_tokens
Your token has been saved to /home/yl2428/.cache/huggingface/token
Login successful.
The current active token is: `new token`
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/launch.py:207: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
W0729 16:59:38.446704 834040 /nfs/roberts/project/pi_mg269/yl2428/ycrc_conda/envs/edm/lib/python3.9/site-packages/torch/distributed/run.py:766] 
W0729 16:59:38.446704 834040 /nfs/roberts/project/pi_mg269/yl2428/ycrc_conda/envs/edm/lib/python3.9/site-packages/torch/distributed/run.py:766] *****************************************
W0729 16:59:38.446704 834040 /nfs/roberts/project/pi_mg269/yl2428/ycrc_conda/envs/edm/lib/python3.9/site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0729 16:59:38.446704 834040 /nfs/roberts/project/pi_mg269/yl2428/ycrc_conda/envs/edm/lib/python3.9/site-packages/torch/distributed/run.py:766] *****************************************
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torchtnt/utils/version.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torchtnt/utils/version.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torchtnt/utils/version.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torchtnt/utils/version.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W729 16:59:48.645193408 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W729 16:59:48.645524621 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W729 16:59:48.645859108 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W729 16:59:48.646367966 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
/nfs/roberts/project/pi_mg269/yl2428/e3_diffusion_for_molecules-main/e3_diffusion_for_molecules-main/qm9/models.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  probs = Categorical(torch.tensor(probs))
/nfs/roberts/project/pi_mg269/yl2428/e3_diffusion_for_molecules-main/e3_diffusion_for_molecules-main/qm9/models.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  probs = Categorical(torch.tensor(probs))
/nfs/roberts/project/pi_mg269/yl2428/e3_diffusion_for_molecules-main/e3_diffusion_for_molecules-main/qm9/models.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  probs = Categorical(torch.tensor(probs))
/nfs/roberts/project/pi_mg269/yl2428/e3_diffusion_for_molecules-main/e3_diffusion_for_molecules-main/qm9/models.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  probs = Categorical(torch.tensor(probs))
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/home/yl2428/.conda/envs/edm/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
Rank 0 - Scale 0.0005:   0%|          | 0/5 [00:00<?, ?it/s]Rank 0 - Scale 0.0005:  20%|██        | 1/5 [11:00<44:00, 660.14s/it]Rank 0 - Scale 0.0005:  40%|████      | 2/5 [22:10<33:18, 666.15s/it]Rank 0 - Scale 0.0005:  60%|██████    | 3/5 [33:27<22:22, 671.29s/it]